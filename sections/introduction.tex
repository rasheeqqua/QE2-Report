\section{Introduction}

Probabilistic Risk Assessment (PRA) is a systematic methodology used to evaluate the risk associated with complex engineered systems, such as nuclear power plants. The classical triplet definition of risk in PRA considers three elements: (i) what can go wrong (scenarios), (ii) how likely it is (probabilities or frequencies), and (iii) what the consequences are (outcomes). PRA provides a structured approach to identify accident scenarios, estimate their likelihood, and assess their potential consequences, thereby supporting risk-informed decision-making for safety and reliability.

PRA models are constructed using two main logical structures: event trees and fault trees. Event trees are used to model the progression of accident scenarios following an initiating event, capturing the sequence of successes and failures of safety functions. Each branch in an event tree represents a possible outcome of a functional event, and the combination of branches forms accident sequences.

Fault trees, on the other hand, are used to model the logical relationship between component-level failures and the failure of system-level functions. Fault trees are constructed using logic gates (AND, OR, k-out-of-n, etc.) to represent how basic events (component failures) combine to cause a top event (system failure). Fault trees can be classified as coherent or non-coherent. Coherent fault trees are those in which the top event is a monotonic function of the basic events, meaning that the occurrence of additional failures cannot decrease the probability of the top event. Non-coherent fault trees include negations (NOT gates) and can represent situations where the success of a component can also lead to system failure.

In PRA, event trees and fault trees are often linked to provide a comprehensive model of accident progression. Two main approaches are used for this integration: fault tree linking (FTL) and event tree linking (ETL) \cite{nusbaumer2013fault}. In the FTL approach, relatively small event trees are used to represent combinations of functional events, and system fault trees are developed for each function. The event tree sequences are translated into a master fault tree, which is then analyzed to identify minimal cut sets or prime implicants. In the ETL approach, larger event trees are constructed, and dependencies between systems are resolved by developing fault trees for functional events such that they do not share basic events. This often requires expanding the event tree to make sequences pairwise disjoint, which can increase the size and complexity of the model.

In both approaches, the number of accident sequences can become very large, especially in multi-hazard scenarios. To manage this complexity, only significant event sequences—those with non-negligible frequencies—are retained, while sequences with very low frequencies are typically dropped during quantification. This truncation is necessary to keep the analysis tractable but introduces approximation.

A key challenge in PRA quantification arises when the model contains non-rare events, i.e., basic events with relatively high probabilities. Traditional quantification algorithms, such as MOCUS, are based on the enumeration of minimal cut sets (for coherent fault trees) or prime implicants (for non-coherent fault trees). However, the number of cut sets or prime implicants can grow exponentially with the size of the model, making exact quantification computationally infeasible for large models.

To address this, a variety of algorithms and approximations have been developed:
\begin{itemize}
    \item \textbf{Traditional algorithms:} Methods like MOCUS and its variants focus on cut set enumeration and are widely used in industry.
    \item \textbf{Decision diagram techniques:} Binary Decision Diagrams (BDD), Zero-suppressed BDD (ZBDD), and Ternary Decision Diagrams (TDD) provide compact representations of Boolean functions and can be used for both exact and approximate quantification.
    \item \textbf{Normal form methods:} Techniques such as d-DNNF, sd-DNNF, and SDD transform the Boolean model into a form that is more amenable to efficient probability calculation.
    \item \textbf{Monte Carlo methods:} These use random sampling to estimate probabilities, which can be effective for very large models but may require a large number of samples for rare events.
\end{itemize}

Approximate methods are often used in conjunction with these algorithms to reduce computational effort. Common approximations include the Rare Event Approximation (REA), Minimal Cut Upper Bound (MCUB), and the application of truncation limits on probability, frequency, or cut set order. While these approximations can make quantification feasible, they may lead to overestimation or underestimation of risk, particularly in the presence of non-rare events or non-coherent logic.

The remainder of this paper is organized as follows. Section 2 provides a detailed overview of PRA, fault trees, event trees, and their integration. Section 3 introduces decision diagram techniques used in PRA quantification, including BDD, ZBDD, TDD, and the recently proposed Zero-Suppressed Ternary Decision Diagram (ZTDD). Section 4 presents a critical review of the ZTDD method, evaluating its methodology and practical applicability. Section 5 compares ZTDD with traditional quantification algorithms, while Section 6 contrasts it with other decision diagram approaches. Section 7 discusses normal form methods, and Section 8 reviews Monte Carlo methods. Section 9 analyzes the application of these quantification methods to advanced nuclear reactor PRA models, focusing on multi-hazard scenarios, computational complexity, and suitability for different use cases. The paper concludes with a summary of findings and recommendations for PRA quantification in large, complex models.
